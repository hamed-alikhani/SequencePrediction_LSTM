{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GithubSequence.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYgCw4WNbDzk"
      },
      "outputs": [],
      "source": [
        "# Load LSTM and other required libraries\n",
        "\n",
        "import numpy as np\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "import sys\n",
        "\n",
        "\n",
        "\n",
        "#Load text data and convert to lowercases (part of the data is available in Github)\n",
        "filename = \"finalconcurrent.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()\n",
        "\n",
        "\n",
        "#Map unique characterss to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "#compute number of characters\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset creation and LSTM mdoel development \n",
        "#Create a sequential dataset of input/output pairs (input: sequence of 10 characters, output: a single character after the input sequence)\n",
        "seq_length = 10\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)\n",
        "\n",
        "\n",
        "\n",
        "#Define LSTM model with 2 hidden layers and dropouts\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.fit(X, y, epochs=400, batch_size=64, callbacks=callbacks_list)\n",
        "\n"
      ],
      "metadata": {
        "id": "63OUvVQeeTUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#implement Beam Search\n",
        "#This function receives the last layer of probabilities and pattern to give the next character elements\n",
        "def create_kresults(prediction,pattern,log_p):\n",
        "  k=3\n",
        "  #create next element [pattern,probability,next_index,result]\n",
        "  n_elements=[[None for i in range(k)],[], [], []]\n",
        "  pat=n_elements[0]\n",
        "  log_p_next=[]\n",
        "  next_index=n_elements[2]    \n",
        "  result=n_elements[3]  \n",
        "  for i in range(k):\n",
        "      index1=numpy.argmax(prediction)\n",
        "      prob1=prediction[0,index1]\n",
        "      result1 = int_to_char[index1]\n",
        "      next_index.append(index1)\n",
        "      log_p_next.append(log_p-np.log(prob1))\n",
        "      result.append(result1)\n",
        "      prediction[0,index1]=0\n",
        "  for i in range(k):\n",
        "      pat[i]=np.array(pattern)\n",
        "      pat[i]=np.append(pat[i],next_index[i])\n",
        "      pat[i]=pat[i][1:len(pat[i])]\n",
        "\n",
        "  n_elements=[pat,log_p_next,next_index,result]\n",
        "  return n_elements\n",
        "\n",
        "#Function of creating str from a pattern\n",
        "def create_str(pattern):\n",
        "    o=[]\n",
        "    for u in range(len(pattern)):\n",
        "        o.append(int_to_char[pattern[u]])\n",
        "    return o\n",
        "    \n",
        "#Function of creating pattern from a str\n",
        "def create_number(pattern):\n",
        "    o=[]\n",
        "    for u in range(len(pattern)):\n",
        "        o.append(char_to_int[pattern[u]])\n",
        "    return o     "
      ],
      "metadata": {
        "id": "_-zBaQ6sfXyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print next characters and their probabilities\n",
        "#Define number of predictions\n",
        "n_prediction=3\n",
        "n=[]\n",
        "for i in range(n_prediction):\n",
        "  if i==0:\n",
        "      x=numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "      x = x / float(n_vocab)\n",
        "      prediction = model.predict(x, verbose=0)\n",
        "      prediction1=np.copy(prediction)      \n",
        "      n_elements=create_kresults(prediction1,pattern,0)\n",
        "      n.append(n_elements)\n",
        "\n",
        "  else:\n",
        "      multi_n_elements=[]\n",
        "\n",
        "      for j in range(k):    \n",
        "          x=numpy.reshape(n_elements[0][j], (1, len(pattern), 1))\n",
        "          x = x / float(n_vocab)\n",
        "          prediction = model.predict(x, verbose=0)\n",
        "          prediction1=np.copy(prediction)\n",
        "          log_p1=n_elements[1][j]\n",
        "          n_elements1=create_kresults(prediction1,n_elements[0][j],log_p1)\n",
        "          multi_n_elements.append(n_elements1)\n",
        "      r=np.concatenate((multi_n_elements[0],multi_n_elements[1],multi_n_elements[2]),axis=1)\n",
        "      r=np.transpose(r)\n",
        "      ordered = sorted(r, key=lambda tup:tup[1]) \n",
        "      ordered=np.reshape(ordered,(np.shape(ordered)))\n",
        "      ordered=np.transpose(ordered)\n",
        "      n_elements=ordered[:,0:k]   \n",
        "      n.append(n_elements)\n",
        "      #print\n",
        "      print(\"next index\",n_elements[2])\n",
        "      print(\"probs\",n_elements[1])\n",
        "      print(\"result\",n_elements[3])\n",
        "      print(\"patterns\",n_elements[0])"
      ],
      "metadata": {
        "id": "FEILHgXFgIbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Nov  4 17:46:45 2020\n",
        "\n",
        "@author: Hamed\n",
        "\"\"\"\n",
        "\n",
        "#Generating random sequences from test database\n",
        "import numpy as np\n",
        "filename = \"Test.txt\"\n",
        "raw_text1 = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text1 = raw_text1.lower()\n",
        "#takeout the enter character\n",
        "raw_text=\"\"\n",
        "for i in range(len(raw_text1)):\n",
        "    if raw_text1[i] != '\\n':\n",
        "        raw_text=raw_text+raw_text1[i]\n",
        "\n",
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "\n",
        "\n",
        "#create integer data\n",
        "data=[]\n",
        "for char in raw_text:\n",
        "    r=char_to_int[char]\n",
        "    data.append(r)\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "#define seqin as the input to the model\n",
        "\n",
        "def create_str(pattern):\n",
        "    o=[]\n",
        "    for u in range(len(pattern)):\n",
        "        o.append(int_to_char[pattern[u]])\n",
        "    return o\n",
        "    \n",
        "#Function of creating pattern from a str\n",
        "def create_number(pattern):\n",
        "    o=[]\n",
        "    for u in range(len(pattern)):\n",
        "        o.append(char_to_int[pattern[u]])\n",
        "    return o  \n",
        "#Function of creating str from a pattern\n",
        "\n",
        "#AR SR BMS\n",
        "stringin1=['a','r', ' ', 'r', ' ', 'r', ' ', 'r', 'q', ' ']\n",
        "seqin=create_number(stringin1)\n",
        "stringout1=['b','r', ' ', 'b', 'z']\n",
        "pattern_outseq=create_number(stringout1)\n",
        "\n",
        "\n",
        "#create all possible output sequences\n",
        "import itertools\n",
        "from random import sample\n",
        "t=[]\n",
        "for i in range(27):\n",
        "    t.append(i)    \n",
        "R=list(itertools.product(t,t,t,t,t,repeat=1)) \n",
        "t=[]\n",
        "for i in range(len(R)):\n",
        "    t.append(list(R[i]))\n",
        "R=t\n",
        "R=sample(R,200000)\n",
        "\n",
        "\n",
        "def evaluate(c,data,seqin1):\n",
        "    x1=[]\n",
        "    numenator=0\n",
        "    prob=0\n",
        "    for o in range(len(c)):\n",
        "        if c[o]+len(seqin1)+1<len(data):\n",
        "            x1.append(data[c[o]+len(seqin1)+1])\n",
        "        \n",
        "            if x1[o]==R[i][j]:\n",
        "                numenator+=1\n",
        "    prob+=(numenator/len(c))\n",
        "    if prob==0:\n",
        "        x2=[]\n",
        "        for o in range(len(c)):\n",
        "            if c[o]+len(seqin1)+2<len(data):\n",
        "                x2.append(data[c[o]+len(seqin1)+2])\n",
        "                if x2[o]==R[i][j]:\n",
        "                    numenator+=1\n",
        "        prob+=(numenator/len(c))*0.5\n",
        "    if prob==0:\n",
        "        x3=[]\n",
        "        for o in range(len(c)):\n",
        "            if c[o]+len(seqin1)+3<len(data):\n",
        "                x3.append(data[c[o]+len(seqin1)+3])\n",
        "                if x3[o]==R[i][j]:\n",
        "                    numenator+=1\n",
        "        prob+=(numenator/len(c))*0.33\n",
        "    if prob==0:\n",
        "        x4=[]\n",
        "        for o in range(len(c)):\n",
        "            if c[o]+len(seqin1)+4<len(data):\n",
        "                x4.append(data[c[o]+len(seqin1)+4])\n",
        "                if x4[o]==R[i][j]:\n",
        "                    numenator+=1\n",
        "        prob+=(numenator/len(c))*0.25\n",
        "    if prob==0:\n",
        "        x5=[]\n",
        "        for o in range(len(c)):\n",
        "            if c[o]+len(seqin1)+5<len(data):\n",
        "                x5.append(data[c[o]+len(seqin1)+5])\n",
        "                if x5[o]==R[i][j]:\n",
        "                    numenator+=1\n",
        "        prob+=(numenator/len(c))*0.2\n",
        "    if prob==0:\n",
        "        prob=0.000001\n",
        "    return -np.log(prob)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "evaluation=[]\n",
        "for i in range(len(R)):\n",
        "    #evaluate R[i]\n",
        "    eva_sequence=0\n",
        "    \n",
        "    for j in range(len(R[i])):\n",
        "        #consider single elements of R[i][j] for evaluation\n",
        "        seqin1=seqin[j:]+R[i][0:j]\n",
        "        ev_element=0\n",
        "        for k in range(len(seqin)):\n",
        "            #look for the seqin in the database\n",
        "            c=[l for l in range(len(data)) if data[l:l+len(seqin1)]==seqin1]\n",
        "            if len(c)==0:\n",
        "                seqin1=seqin1[1:]\n",
        "            else:\n",
        "                #evaluate R[i][j]if you found a match of a subsequence from the input sequence in the database\n",
        "                ev_element=evaluate(c,data,seqin1)*(k) if k!=0 else evaluate(c,data,seqin1)\n",
        "        eva_sequence += ev_element\n",
        "    #check the existence of ' ',' ' in the sequence\n",
        "    t=0\n",
        "    er=0\n",
        "    while t<len(R[i])-1:\n",
        "        if R[i][t]==R[i][t+1]==char_to_int[' ']:\n",
        "            er+=1\n",
        "        t+=1\n",
        "    if er>0:\n",
        "        eva_sequence = er*100+eva_sequence\n",
        "    evaluation.append([R[i],eva_sequence])\n",
        "    if i%1000==0:\n",
        "        print(i) \n",
        "evaluation=sorted(evaluation, key=lambda tup:tup[1]) \n",
        "\n",
        "\n",
        "np.save('evaluation.npy',evaluation)\n",
        "\n",
        "np.save('evaluation1.npy',evaluation)\n",
        "a=np.load('evaluation.npy')\n",
        "a1=np.load('evaluation1.npy')\n",
        "\n",
        "pattern_outseq=pattern_outseq[0:5]\n",
        "#evaluate output seq of the model\n",
        "R=[pattern_outseq,pattern_outseq]\n",
        "evaluation1=[]\n",
        "for i in range(len(R)):\n",
        "    #evaluate R[i]\n",
        "    eva_sequence=0\n",
        "    \n",
        "    for j in range(len(R[i])):\n",
        "        #consider single elements of R[i][j] for evaluation\n",
        "        seqin1=seqin[j:]+R[i][0:j]\n",
        "        ev_element=0\n",
        "        for k in range(len(seqin)):\n",
        "            #look for the seqin in the database\n",
        "            c=[l for l in range(len(data)) if data[l:l+len(seqin1)]==seqin1]\n",
        "            if len(c)==0:\n",
        "                seqin1=seqin1[1:]\n",
        "            else:\n",
        "                #evaluate R[i][j]if you found a match of a subsequence from the input sequence in the database\n",
        "                ev_element=evaluate(c,data,seqin1)*(k) if k!=0 else evaluate(c,data,seqin1)\n",
        "        eva_sequence += ev_element\n",
        "    evaluation1.append([R[i],eva_sequence])\n",
        "evaluation1=sorted(evaluation1, key=lambda tup:tup[1]) \n",
        "\n",
        "\n",
        "c=[]\n",
        "for i in range(len(R)):\n",
        "    c.append(evaluation[i][1])\n",
        "\n",
        "# #save to excel\n",
        "# import pandas as pd\n",
        "# data1=pd.DataFrame(c)\n",
        "# datatoexcel=pd.ExcelWriter(\"FromPython.xlsx\")\n",
        "\n",
        "# data1.to_excel(datatoexcel,sheet_name='Sheet1')\n",
        "# datatoexcel.save()\n",
        "\n",
        "# #read from the file\n",
        "# from openpyxl import load_workbook\n",
        "# xl=pd.ExcelFile(\"FromPython.xlsx\")\n",
        "# df=xl.parse(\"Sheet1\")\n",
        "# c1=df[\"Evaluation\"]\n",
        "\n",
        "from random import sample\n",
        "f1=sample(c,200000)\n",
        "f2=sample(c,200000)\n",
        "f3=sample(c,200000)\n",
        "f4=sample(c,200000)\n",
        "f5=sample(c,200000)\n",
        "f6=sample(c,100000)\n",
        "\n",
        "\n",
        "c1=c+f1+f2+f3+f4+f5+f6\n",
        "c1=c1.sort()\n",
        "np.save(\"Myfile5.npy\",c1)\n",
        "\n",
        "\n",
        "\n",
        "a = np.load(\"Myfile5.npy\")\n",
        "np.percentile(a,0.6)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# plt.hist(c10, bins=60)\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=[10,8])\n",
        "n, bins, patches = plt.hist(a, bins=60, color='#0504aa',alpha=0.7, rwidth=0.9)\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.xticks(fontsize=30)\n",
        "plt.yticks(fontsize=30)\n",
        "plt.title('Possible output sequences score- Case #6' ,fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4HTw2nVmhN74"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}